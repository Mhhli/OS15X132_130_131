			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+

---- GROUP ----
李树楠 <10132510132@ecnu.edu>
罗澜鑫 <10132510131@ecnu.edu>
李  震 <10132510130@ecnu.edu>

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

- In thread.h, added variable to thread struct:
	
	int64_t ticks_blocked;
	- Record the time the thread has been blocked.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

In timer_sleep():
1) Check for valid ticks argument (ticks_blocked > 0).
2) Record the interrupt status of current thread.
3) Get the pointer of current thread.
4) Set the sleeping time to ticks_blocked of current thread.
5) Block the thread.
6) Recover the interrupt status.

In the timer interrupt handler(timer_interrupt()):
1) Invoke function thread_foreach() to do blocked_thread_check() for every thread.
2) The paramenter of thread_forech()————blocked_thread_check() is defined in thread.h and 
   realized in thread.c.
3) The function blocked_thread_check() is to check the thread. If the thread is blocked and
   the value ticks_blocked > 0, ticks_blocked will decrease. Then,if ticks_blocked = 0,the 
   thread will be unblock and insert into ready_list.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

Note that by keeping the all_list(all thread list) in sorted order in the function thread_unblock(),
this minimize the time in the interrupt handler. Thus, thr handler does not have to iterate through
the entire all thread list at every interrupt.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Note that the ticks_blocked is a local variable. 

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

In timer_sleep(), by invoking function intr_disable() to make interrupts turn off temprorarily
to set ticks to ticks_blocked of thread. After that interrupts will turn on and can operate the 
variable.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We considered to add a global variable "static struct list sleep_list" in timer.c to list that 
keeps track of the threads which are sleeping. While this would take up more space in memory.
Thus, we using this design to save space.


            		 PRIORITY SCHEDULING
            		 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.h, the following variables are added to the thread struct:

	int old_priority;
	- The baseline (non-donated) priority of the thread.

	struct list donate_lock_list;
	- The list of locks which has holder and is donated. 

	struct lock *wanting_lock;
	- The lock the thread is waiting on (NULL if not waiting on any lock).

In synch.h, the following variables are added to the lock struct:

	int older_priority;
	- The holder's priority (non-donated).

	int later_priority;
	- The new priority among the threads acquiring the lock.

	bool is_donated;
	- The holder of lock is donated.

	struct list_elem elem;
	- List element for priority donation.

In synch.h, the following variables are added to the semaphore_elem struct:

	int sema_priority;
	- Compare the priority of semaphore_elem and a structure objrct that 
	  contains it.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

A, B, C are locks
H1, H2, M, L are threads

    A	
H1 ---> M
    B	   C
H2 ---> M ---> L

M's donation list: H1, H2
L's donation list: M

M's wait on lock: C
L's wait on lock: NULL

M's current donated priority is max(H1, H2, M).
L's current donated priority is max(L, M).


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

In a semaphore, the list of waiters denotes the threads waiting for the
semaphore to be upped. Thus, waiters are inserted such that the front
thread has the highest priority. Note that this waiters list is also
sorted after the semaphore is released.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

1) If the holder of lock is not null and its priority < the priority of current 
   thread,do the follow step 2-5.
2) If lock is non-donated, the holder of lock updates its old_priority
   variable to the current lock.
3) The current thread updates its wanting_lock variable to the current lock.
   The holder of lock updates its priority variable to the current thread priority.
   The lock updates its later_priority variable to the current thread priority.
4) Invoking nest_donate() for the holder of lock to do nested donation handle.
5) Adding lock to the lock holder's donations list and set lock is_donated variable
   to be true.
6) Update the lock holder to be the current thread.
   Update current thread's wanting_lock variable to be NULL;
   Set lock older_priority variable to be current thread's priority.

Priority is donated iteratively via the following process by using Recursion Algorithm:
	- function  : nest_donate()
	- paramenter: thread *p
	1) if p's wanting_lock is NULL,return;
	2) if current thread's priority > the holder's priority of p's wanting_lock,
	   update the holder's priority and later_priority of p's wanting_lock to be 
	   current thread's priority. Then return nest_donate(),the paramenter is the
	   holder of p's wanting_lock.
	3) if current thread's priority <= the holder's priority of p's wanting_lock,return.
	
>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

1) If lock is donated, do follow steps 2-4;
2) Remove lock's elem from list;
3) If current thread's donate_lock_list is not null, get a lock pointer to the front list of 
   donate_lock_list and set current thread's priority to be the pointer's later_priority.
4) If current thread's donate_lock_list is empty, set current thread's priority to be lock's
   older_priority.
5) The lock holder is updated to NULL and set lock be not donated.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A potential race condition would be while the thread priority variable is being updated to the
new priority, the interrupt handler is writing to the priority variable. Thus, these conflicting
writes could mangle the priority variable, therefore being a race condition.

We use variable wanting_lock to realize threads to get resourse.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We only know this design before we talk about other group and search on the Internet. Maybe there is
a better design, but this is suited for us.

           		   ADVANCED SCHEDULER
           		   ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.h, the following variable are added to the thread struct:

	int nice;
	- The thread's current nice value.

	int recent_cpu;
	- The thread's most recently calculate recent_cpu value.

In thread.c, the following global variable is added:

	static int load_avg;
	- The system's most recently calculated load average value

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

Assume time slice = 4 ticks.

timer  recent_cpu    priority   thread	     ready
ticks   A   B   C   A   B   C   to run	     list
-----  --  --  --  --  --  --   ------	    ------
 0     0   0   0   63  61  59     A          B, C
 4     4   0   0   62  61  59     A          B, C
 8     8   0   0   61  61  59     B          A, C
12     8   4   0   61  60  59     A          B, C
16     12  4   0   60  60  59     B          A, C
20     12  8   0   60  59  59     A          C, B
24     16  8   0   59  59  59     C          B, A
28     16  8   4   59  59  58     B          A, C
32     16  12  4   59  58  58     A          C, B
36     20  12  4   58  58  58     C          B, A

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

Yes, it is unclear if two threads have equal priority, which thread is supposed to run. I used the
following rules:
1) If the running thread has the highest priority and so does a ready thread and the running thread 
reached its time slice, the running thread continues to run. This is equivalent to all highest priority 
threads running round robin.
2) If the scheduler has to choose between multiple ready threads, it chooses the one that has been run 
the least recently (placed first on the ready list).

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

Due to the precise nature in which the scheduler variables needed to be updated, most of the computation 
needs to be done within the interrupt handler. However, I found that the currently running thread's priority
only needs to be updated every 4 ticks, as it is the only thread that changes values of recent_cpu. 
Every second, however, the load average, recent_cpu and priority has to be recalculated over all threads, 
which is expensive. Thus, for a system with a lot of threads, this may be an inadvisable scheduling algorithm 
as it is likely to affect performance.

The only computation done outside the interrupt handler is when resetting the nice value, but the interrupts 
have to be turned off. This is because resetting nice also changes the priotity, which is read / written in the
interrupt handler.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Advantages:
- Simple to understand since no locking of thread variables (only turn off
interrupts).
- Minimal adding of extra variables, kernel threads remain relatively
small. Also makes for easier readability.

Disadvantages:
- Performance suffers due to turning off interrupts instead of locking
variables.
- Ordered inserting and sorting lists takes O(n) and O(n log n)
respectively. Using binary tree / other more efficient data structures
may be needed. (Also, bad caching in linked lists)

To refine my design, I would implement the following features:
- Automatic deadlock detection
- Use locks for variables instead of turning off interrupts (if possible)

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We implemented fixed-point math in a header file. The conversions between integers and fixed-point 
and arithmetic was abstracted away in this file. We used the standard functions as described in the 
Pintos documentation and search some on the Internet,and called these functions in my mlqfs calculation 
functions in thread.h. Abstracting the fixed-point functions allowed for better readability when 
calculating the mlqfs thread.c functions.

          		     SURVEY QUESTIONS
           		     ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

This assignment was quite challenging and took we more than a week straight to complete. We found figuring out 
the data structures for priority donation to be quite challenging.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

We felt dealing with synchronization gave us newfound respect for kernel developers who develop OS's used on 
multi-processor hardware.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

We would give more hints with regards to the priority donation problem.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

We think TAs can communicate with student not only by Wechat but also other ways.

>> Any other comments?

Ah, we have finished this project. Although we search a lot on the Internet, we have known a lot about this project.
We know OS deeper.
